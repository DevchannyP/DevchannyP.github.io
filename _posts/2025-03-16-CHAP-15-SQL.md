---
layout: post
title: "CHAP 15. MariaDB 실무 활용 사례 & 예제 "
date: 2025-03-16
categories: [sql]
tags: [Database, SQL]
thumbnail: /assets/img/post-thumbnails/intro15.png
author: Devchanny
---

# 📌 1️⃣ 대량 데이터 처리 (Big Data Handling)

| 요소 | 설명 | 예시 | 추가 보강 |
| --- | --- | --- | --- |
| **파티셔닝(Partitioning)** | 테이블을 특정 기준으로 물리적으로 분리해 쿼리 속도 향상 | 월별 주문 테이블 파티션 | **주의**: WHERE 절이 파티션 키에 맞지 않으면 오히려 성능 저하 |
| **Bulk Insert & Load** | 대량 데이터 입력 시 한 번에 묶어서 처리 | `LOAD DATA INFILE` 사용 | **주의**: Foreign Key, Unique 제약조건 해제 후 처리하면 더 빠름 |
| **Batch Update/Insert** | 다수의 데이터 변경 시 **트랜잭션 & 배치로 나눠 처리** | 1000건씩 커밋 처리 | 너무 많은 건수 한 번에 처리 시 **InnoDB buffer pool** 초과 위험 |
| **병렬 처리** | Application 레벨에서 병렬 쿼리 실행 | 멀티 스레드로 분산 처리 | DB Connection Pool 크기 적정 조정 필요 (과부하 방지) |

---

### 🎬 **비유 보강: 물류센터에서 대량 택배 처리**

- **지역별 창고(파티셔닝)** → 구역별 구분, 특정 구역에서만 찾기 빠름
- **대형 트럭 한 방에(Bulk Insert)** → 여러 박스 한 번에 입고, 하지만 너무 많으면 적재 불가
- **작업조별로 나눠서(Batch)** → 1000개씩 나눠 포장, 한 번에 다 하면 혼잡
- **여러 창고에서 동시 출하(병렬 처리)** → 출하 게이트마다 동시에 출고, 단 직원 수(연결 수)는 제한 필요

---

### 추가 실무 팁:

- **LOAD DATA INFILE**은 **LOCAL** 옵션을 적절히 사용해야 보안 이슈 피할 수 있음
- **파티셔닝 후 인덱스 재구성**을 통해 파티션 내 효율 향상 가능

---

---

# 📜 **2️⃣ 로그 데이터 분석 (Log Data Analysis)**

### 📌 **핵심 개념**

| 방법 | 설명 | 예시 | 추가 보강 |
| --- | --- | --- | --- |
| **ETL 프로세스** | 로그 수집(Extract), 정제(Transform), 저장(Load) | Raw 로그 → 정제 테이블 | **로그 적재 주기**에 따른 I/O 병목 고려 |
| **Full-Text Search 활용** | 로그 메시지 내 특정 키워드 빠르게 검색 | `FULLTEXT INDEX` 사용 | **대량 로그에서는 Elasticsearch 연동**이 더 효율적일 때도 |
| **윈도우 함수 활용** | 시간 순서 분석, 이벤트 간격 분석 | `ROW_NUMBER()`, `LAG()` 등 | 대량 데이터 시 **파일 정렬 공간(temp space)** 확보 필요 |
| **JSON 데이터 처리** | JSON 형식 로그 파싱 | `JSON_EXTRACT()` | JSON 구조가 너무 복잡할 땐 **정규화 테이블로 전환 고려** |

---

### 🎬 **비유 보강: CCTV 영상 분석 시스템**

- **영상 수집(ETL)** → 매일 CCTV 영상 수집, 필요 없는 부분 잘라내고 저장
- **키워드 검색(Full-Text)** → "빨간 옷 입은 사람" 검색
- **이동 경로 확인(윈도우 함수)** → 사람 이동 시간, 위치 분석
- **AI 영상 해석(JSON)** → 영상에 달린 다양한 태그(JSON) 해석

---

---

# 📝 **3️⃣ 실무에서 많이 쓰이는 SQL 패턴**

| 패턴 | 설명 | 예시 | 추가 보강 |
| --- | --- | --- | --- |
| **Upsert (Insert or Update)** | 데이터 있으면 UPDATE, 없으면 INSERT | `INSERT ... ON DUPLICATE KEY UPDATE` | 대량 데이터 시 **Batch Upsert + 트랜잭션**으로 성능 향상 |
| **Pivot / Unpivot** | 컬럼을 행으로, 행을 컬럼으로 변환 | 조건부 집계 + CASE | **동적 Pivot** 필요 시, 애플리케이션 레벨에서 처리하는 경우도 많음 |
| **Pagination 쿼리** | 대용량 데이터에서 페이지 단위 조회 | `LIMIT` + `OFFSET` | 페이지 번호가 커지면 **OFFSET 성능 저하 → ID 기반 커서 방식 추천** |
| **Recursive Query** | 트리 구조 조회 | `WITH RECURSIVE` | **무한 루프 방지 위해 MAXRECURSION 제한 설정 권장** |

---

### 🎬 **비유 보강:**

- **Upsert = 고객 명단 업데이트, 기존 고객이면 정보 갱신, 없으면 추가**
- **Pivot = 가로로 된 재고표를 세로로 재배치**
- **Pagination = 책 넘기기 → 처음 페이지는 빠르나, 뒷페이지로 갈수록 느려질 수 있음**
- **Recursive = 조직도 상사 → 상사 → 최상위 대표까지 올라가기, 너무 깊으면 무한 루프 주의**

---

---

# 🏢 **4️⃣ 데이터 웨어하우스 구축**

### 📌 **핵심 개념 추가**

| 요소 | 설명 | 추가 보강 |
| --- | --- | --- |
| **ETL 파이프라인** | 데이터 수집/정제/저장 자동화 | Apache NiFi, Airflow 같은 외부 도구와 연계 실무에서 자주 사용 |
| **Star Schema** | Fact + Dimension 테이블 구성 | Dimension 테이블은 **변경에 대비해 Slowly Changing Dimension(SCD) 전략 적용** |
| **대량 조회 최적화** | 파티셔닝, 인덱스 활용 | **InnoDB → Columnstore 스토리지(MariaDB Enterprise)** 검토 가능 |
| **OLAP 쿼리 최적화** | 다차원 분석 쿼리 튜닝 | **Materialized View로 미리 집계된 데이터 유지** 시 성능 UP |

---

### 🎬 **비유 보강: 백화점 매출 분석 시스템**

- 매장별/월별로 **판매 데이터 수집(ETL)**
- 중앙에 **매출 데이터(Fact)**, 주변에 **고객/상품/매장 정보(Dimension)**
- 전 지점 비교, 전월 대비 분석 → **OLAP 쿼리**
- 자주 보는 리포트는 미리 계산해 **보고서(물리화 뷰)로 저장**

---

---

# 📋 **🔖 보강된 노션 요약**

---

# 🚀 **MariaDB 실전 활용 사례**

---

### 🏗️ **1. 대량 데이터 처리**

- ✅ 파티셔닝으로 대규모 테이블 쿼리 속도 향상
    - 주의: WHERE 조건 파티션 키 최적화
- ✅ Bulk Insert, Batch 처리로 I/O 최소화
    - Foreign Key 비활성화 시 처리 속도 향상
- ✅ 병렬 처리 → 적절한 Connection Pool 설정
- 🎬 **물류센터: 창고 구역별 정리 + 트럭, 작업조 분리**

---

### 📜 **2. 로그 데이터 분석**

- ✅ ETL로 로그 정제 & 적재
    - 주기적 배치로 I/O 병목 예방
- ✅ Full-Text Search, JSON 함수 활용
    - 대규모일 경우 Elasticsearch 연계 검토
- ✅ 윈도우 함수 → 이벤트 간 간격 분석
- 🎬 **CCTV 영상 분석 시스템: 특정 시간대, 위치, 사람 추적**

---

### 📝 **3. 실무 SQL 패턴**

- ✅ Upsert → Batch 처리로 효율화
- ✅ Pivot/Unpivot → 동적 Pivot 시 애플리케이션 연계
- ✅ Pagination → 커서 기반 추천
- ✅ Recursive → MAXRECURSION 설정
- 🎬 **고객명단 관리, 엑셀 변환, 책장 넘기기, 조직도 탐색 비유**

---

### 🏢 **4. 데이터 웨어하우스 구축**

- ✅ ETL 파이프라인 + 외부 도구 연계
- ✅ Star Schema 구성 → SCD 적용
- ✅ OLAP 쿼리 + Materialized View 적극 활용
- 🎬 **백화점 매출 분석: 지점별, 고객별, 시간대별 빠른 리포트 제공**
